{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nariakiiwatani/easylazyscrap_speech/blob/main/easylazyscrap_speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests openai gtts newspaper3k langchain faiss-gpu tiktoken pydub eyed3"
      ],
      "metadata": {
        "id": "FVx5w3KZMj20"
      },
      "id": "FVx5w3KZMj20",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b26fee0d",
      "metadata": {
        "id": "b26fee0d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# for local run\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv()\n",
        "\n",
        "# for colab run\n",
        "import json\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/secrets/openai.json') as jsonfile:\n",
        "    for i, (k,v) in enumerate(json.load(jsonfile).items()):\n",
        "      os.environ[k] = v\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d78574fa",
      "metadata": {
        "id": "d78574fa"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "from pytz import timezone\n",
        "\n",
        "def generate_recent_page_urls(base_url, base_date, within_days):\n",
        "    recent_page_urls = []\n",
        "    for i in range(within_days):\n",
        "        date_string = (base_date - datetime.timedelta(days=i)).strftime(\"%Y%%2F%m%%2F%d\")\n",
        "        page_url = f\"{base_url}/scrap_{date_string}/text\"\n",
        "        recent_page_urls.append(page_url)\n",
        "    return recent_page_urls\n",
        "\n",
        "within_days = 7\n",
        "base_url = \"https://scrapbox.io/api/pages/easylazyscrap\"\n",
        "now = datetime.datetime.now()\n",
        "today = now.astimezone(timezone('Asia/Tokyo'))\n",
        "# yesterday\n",
        "base_date = today - datetime.timedelta(days=1)\n",
        "recent_page_urls = generate_recent_page_urls(base_url, base_date, within_days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27e09a4b",
      "metadata": {
        "id": "27e09a4b"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import newspaper\n",
        "import re\n",
        "\n",
        "def fetch_links_from_page(url):\n",
        "    links = []\n",
        "    response = requests.get(url)\n",
        "    for line in response.text.splitlines():\n",
        "        match = re.search('\\[(.*?) ((?:https?|ftp):\\/\\/?[\\w/\\-?=%.]+\\.[\\w/\\-?=%.]+)\\s*\\]', line)\n",
        "        if match:\n",
        "            link_text = match.group(1)\n",
        "            link_url = match.group(2)\n",
        "            links.append((link_text, link_url))\n",
        "    return links\n",
        "\n",
        "def get_article(url):\n",
        "    article = newspaper.Article(url)\n",
        "    article.download()\n",
        "    article.parse()\n",
        "    return article.text\n",
        "\n",
        "links = []\n",
        "articles = []\n",
        "for page_url in recent_page_urls:\n",
        "    new_links = fetch_links_from_page(page_url)\n",
        "    links.extend(new_links)\n",
        "    for title, url in new_links:\n",
        "        try:\n",
        "          article = get_article(url)\n",
        "          if article != \"\":\n",
        "              articles.append((title, article))\n",
        "        except:\n",
        "          next\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cec74873",
      "metadata": {
        "id": "cec74873"
      },
      "outputs": [],
      "source": [
        "choice = 8\n",
        "choice = min(choice, len(articles))\n",
        "\n",
        "idx = np.random.choice(np.arange(len(articles)), choice, replace=False)\n",
        "\n",
        "articles = list(np.array(articles)[idx])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ce456e6",
      "metadata": {
        "scrolled": true,
        "id": "2ce456e6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "import faiss\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=140, chunk_overlap=0, separator=\"\\n\")\n",
        "res = faiss.StandardGpuResources()\n",
        "flat_config = faiss.GpuIndexFlatConfig()\n",
        "\n",
        "clustered = []\n",
        "def clusterize(text, n):\n",
        "    documents = text_splitter.create_documents([text])\n",
        "    texts = [doc.page_content.replace(\"\\n\\n\", \"\") for doc in documents]\n",
        "\n",
        "    response = openai.Embedding.create(input=texts, model=\"text-embedding-ada-002\")\n",
        "    embeds = [record['embedding'] for record in response['data']]\n",
        "    embeds_np = np.array(embeds).astype('float32')\n",
        "    if(embeds_np.shape[0] == 0):\n",
        "      return False\n",
        "    clusters_num = min(embeds_np.shape[0], 5)\n",
        "    index = faiss.GpuIndexFlatL2(res, embeds_np.shape[1], flat_config)\n",
        "    index.add(embeds_np)\n",
        "\n",
        "    kmeans = faiss.Kmeans(d=embeds_np.shape[1], k=clusters_num, niter=20, verbose=True)\n",
        "    kmeans.train(embeds_np)\n",
        "    clusters = kmeans.index.search(embeds_np, 1)[1].flatten()\n",
        "\n",
        "    # 最も近いクラスタ中心点との距離を計算し、クラスタ中心点に近いものからn個だけ残して、それ以外を除外する\n",
        "    clustered_sentences = {}\n",
        "    for i, label in enumerate(clusters):\n",
        "        if label not in clustered_sentences:\n",
        "            clustered_sentences[label] = []\n",
        "\n",
        "        distances = np.linalg.norm(embeds_np[i] - kmeans.centroids[label])\n",
        "        clustered_sentences[label].append((texts[i], distances))\n",
        "\n",
        "    # 中心点に近いものからn個だけ残す\n",
        "    for label, cluster in clustered_sentences.items():\n",
        "        sorted_cluster = sorted(cluster, key=lambda x: x[1])\n",
        "        clustered_sentences[label] = [c[0] for c in sorted_cluster[:n]]\n",
        "\n",
        "    return clustered_sentences\n",
        "\n",
        "def pick(src, num):\n",
        "    sorted_list = sorted(src.items(), key=lambda x: len(x[1]), reverse=True)\n",
        "    return dict(sorted_list[:num])\n",
        "\n",
        "pick_cluster = 3\n",
        "pick_inside_cluster = 3\n",
        "for (title, article) in articles:\n",
        "  result = clusterize(article, pick_inside_cluster)\n",
        "  if result != False:\n",
        "    clustered.append((title, pick(result, pick_cluster)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9be445c6",
      "metadata": {
        "scrolled": true,
        "id": "9be445c6"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain import OpenAI\n",
        "\n",
        "prompt_template = \"\"\"以下の内容について200字程度の簡潔な要約を日本語で作成してください:\n",
        "\n",
        "\"{text}\"\n",
        "\n",
        "簡潔な要約:\"\"\"\n",
        "PROMPT = PromptTemplate(template=prompt_template, input_variables=['text'])\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "\n",
        "def summarize(clusters):\n",
        "    cluster_summaries = []\n",
        "    for cluster_sentences in clusters.values():\n",
        "        docs = [Document(page_content=sentence) for sentence in cluster_sentences]\n",
        "        chain = load_summarize_chain(\n",
        "            OpenAI(\n",
        "                model_name=\"text-davinci-002\",\n",
        "                temperature=0.7,\n",
        "            ),\n",
        "            chain_type=\"map_reduce\",\n",
        "            map_prompt=PROMPT,\n",
        "            combine_prompt=PROMPT,\n",
        "        )\n",
        "        summary = chain.run(input_documents=docs, token_max=2000)\n",
        "        cluster_summaries.append(summary)\n",
        "    return cluster_summaries\n",
        "\n",
        "summaries = [(title, summarize(cluster)) for (title, cluster) in clustered]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dd9d1b3",
      "metadata": {
        "id": "3dd9d1b3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "basename = today.strftime(\"%Y_%m_%d\")\n",
        "\n",
        "export_directory = f\"/content/drive/MyDrive/easylazyscrap/episodes/{basename}\"\n",
        "if not os.path.exists(export_directory):\n",
        "    os.makedirs(export_directory)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "945c2b1c",
      "metadata": {
        "id": "945c2b1c"
      },
      "outputs": [],
      "source": [
        "to_date = base_date.strftime(\"%Y年%-m月%-d日\")\n",
        "from_date = (base_date - datetime.timedelta(days=within_days-1)).strftime(\"%Y年%-m月%-d日\")\n",
        "\n",
        "podcast_script = f\"\"\"<![SOUND[start.wav]]>\n",
        "今週の、イージーレイジースクラップ。\n",
        "イージーレイジースクラップは、スクラップボックス上で「あとで読む」を共有できる、半匿名のブックマーク共有サービスです。\n",
        "この番組では、今週、イージーレイジースクラップに投稿された内容から、いくつかをピックアップして紹介します。\n",
        "\n",
        "今回は、{from_date}から、{to_date}のスクラップを紹介します。\n",
        "<![SOUND[start_scrap.wav]]>\n",
        "\"\"\"\n",
        "\n",
        "for i, (title, summary) in enumerate(summaries):\n",
        "    text = ''.join(summary).replace('\\n', '')\n",
        "    podcast_script += f\"<![CHAPTER[{title}]]>{title}\\n{text}<![SOUND[inter.wav]]>\\n\\n\"\n",
        "\n",
        "podcast_script += \"\"\"今週の、ピックアップは、以上です。\n",
        "<![BLANK[1000]]>\n",
        "最後に、今週寄せられた、全てのスクラップのタイトルを読み上げます。\n",
        "<![CHAPTER[今週のスクラップ一覧]]>\n",
        "<![SOUND[click.wav]]>\n",
        "\"\"\"\n",
        "\n",
        "for i, (title, url) in enumerate(links):\n",
        "    podcast_script += f\"{title}<![SOUND[click.wav]]>\\n\"\n",
        "\n",
        "podcast_script += \"\"\"\n",
        "今週、寄せられたリンクは、以上です。\n",
        "これで、今週のイージーレイジースクラップを終わります。\n",
        "\n",
        "イージーレイジースクラップへは、どなたでもご参加いただけます。\n",
        "概要欄のリンクから、参加方法をご確認ください。\n",
        "ありがとうございました！\n",
        "<![SOUND[end.wav]]>\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import gtts\n",
        "import os\n",
        "import re\n",
        "import tempfile\n",
        "\n",
        "def make_speech(script, options={}):\n",
        "    opt = {**{'playback_speed':1.25}, **options}\n",
        "    text_to_speech = gtts.gTTS(script, lang=\"ja\", lang_check=False)\n",
        "    try:\n",
        "      fp = tempfile.NamedTemporaryFile()\n",
        "      text_to_speech.save(fp.name)\n",
        "      speech = AudioSegment.from_mp3(fp.name)\n",
        "      return speech.speedup(playback_speed=opt['playback_speed'])\n",
        "    except:\n",
        "      return None\n",
        "\n",
        "def create_audio(script, output_file_name, playback_speed=1.0, sound_effects_dir='./'):\n",
        "    pattern = r'<!\\[(.*?)\\[(.*?)\\]\\]>'\n",
        "    parts = re.split(pattern, ' '+script)\n",
        "\n",
        "    audio_segments = []\n",
        "    chapters = []\n",
        "    current_time_ms = 0\n",
        "    for i, part in enumerate(parts):\n",
        "        if i % 3 == 0:  # テキスト部分\n",
        "          speech = make_speech(part)\n",
        "          print(speech)\n",
        "          if speech:\n",
        "            audio_segments.append(speech)\n",
        "            current_time_ms += len(speech)\n",
        "        elif i % 3 == 1:  # 指示種別\n",
        "            continue  # 指示種別を次のループで処理するため、ここではスキップ\n",
        "        else:  # 指示内容\n",
        "            instruction_type = parts[i - 1]\n",
        "            if instruction_type == 'SOUND':\n",
        "                sound_effect_file_path = os.path.join(sound_effects_dir, part)\n",
        "                sound_effect = AudioSegment.from_wav(sound_effect_file_path)\n",
        "                audio_segments.append(sound_effect)\n",
        "                current_time_ms += len(sound_effect)\n",
        "            elif instruction_type == 'BLANK':\n",
        "                blank_duration_ms = int(part)\n",
        "                blank_segment = AudioSegment.silent(duration=blank_duration_ms)\n",
        "                audio_segments.append(blank_segment)\n",
        "                current_time_ms += len(blank_segment)\n",
        "            elif instruction_type == 'CHAPTER':\n",
        "                chapters.append((current_time_ms, part))\n",
        "            else:\n",
        "              speech = make_speech(instruction_type + ' ' + part)\n",
        "              if speech:\n",
        "                audio_segments.append(speech)\n",
        "                current_time_ms += len(speech)\n",
        "\n",
        "    # 全ての音声データを結合\n",
        "    final_audio = audio_segments[0]\n",
        "    for segment in audio_segments[1:]:\n",
        "        final_audio += segment\n",
        "\n",
        "    final_audio.export(output_file_name, format=\"mp3\")\n",
        "\n",
        "    return chapters\n",
        "\n",
        "audio_file_path = os.path.join(export_directory, f\"{basename}.mp3\")\n",
        "sound_directory = \"/content/drive/MyDrive/easylazyscrap/sounds\"\n",
        "\n",
        "chapters = create_audio(podcast_script, audio_file_path, 1.25, sound_directory)"
      ],
      "metadata": {
        "id": "bGuhlhYMTZx1"
      },
      "id": "bGuhlhYMTZx1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import eyed3\n",
        "from eyed3.id3.tag import Tag\n",
        "\n",
        "def add_chapters_to_mp3(mp3_file_path, chapters):\n",
        "    # MP3ファイルをロード\n",
        "    audio_file = eyed3.load(mp3_file_path)\n",
        "\n",
        "    audio_file.tag = Tag()\n",
        "    toc = audio_file.tag.table_of_contents.set(b\"toc\", toplevel=True,\n",
        "                                    description=u\"Table of Contents\")\n",
        "\n",
        "    audio_length_s = audio_file.info.time_secs\n",
        "\n",
        "    # 各チャプターを追加\n",
        "    for i, chapter in enumerate(chapters):\n",
        "        start_time_ms, title = chapter\n",
        "        start_time_s = start_time_ms / 1000\n",
        "        # 次のチャプターの開始時間またはオーディオの全体の長さを終了時間として使用\n",
        "        if i + 1 < len(chapters):\n",
        "            end_time_s = chapters[i + 1][0] / 1000\n",
        "        else:\n",
        "            end_time_s = audio_length_s\n",
        "\n",
        "        chp = audio_file.tag.chapters.set(f\"chp{i}\".encode('utf-8'), (start_time_s, end_time_s))\n",
        "        chp.title = title\n",
        "        toc.child_ids.append(chp.element_id)\n",
        "\n",
        "    # タグを保存\n",
        "    audio_file.tag.save()\n",
        "\n",
        "add_chapters_to_mp3(audio_file_path, chapters)"
      ],
      "metadata": {
        "id": "U3mIoLdvpnqw"
      },
      "id": "U3mIoLdvpnqw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "def read_chapters_from_mp3(mp3_file_path):\n",
        "    # MP3ファイルをロード\n",
        "    audio_file = eyed3.load(mp3_file_path)\n",
        "\n",
        "    # チャプター情報を読み取る\n",
        "    toc = audio_file.tag.table_of_contents.get(b\"toc\")\n",
        "    for child_id in toc.child_ids:\n",
        "        chp = audio_file.tag.chapters.get(child_id)\n",
        "        pprint(vars(chp))\n",
        "        start_time, end_time = chp.times\n",
        "        print(f\"Chapter {chp.element_id.decode('utf-8')}: {start_time} - {end_time}, title: {chp.title}\")\n",
        "\n",
        "#read_chapters_from_mp3(audio_file_path)"
      ],
      "metadata": {
        "id": "0AxdKkbQv6dL"
      },
      "id": "0AxdKkbQv6dL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef2715af",
      "metadata": {
        "id": "ef2715af"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "Audio(audio_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9df24c33",
      "metadata": {
        "id": "9df24c33"
      },
      "outputs": [],
      "source": [
        "description = \"\"\"easylazyscrapは、Scrapbox上で「あとで読む」を共有できる、半匿名のブックマーク共有サービスです。\n",
        "この番組では、今週投稿されたリンクからランダムにいくつかをピックアップして、その内容を紹介します。\n",
        "\n",
        "easylazyscrapへの参加方法は、下記のリンクからご確認ください。\n",
        "https://scrapbox.io/easylazyscrap/easylazyscrap%E3%81%AE%E4%BD%BF%E3%81%84%E6%96%B9\n",
        "\"\"\"\n",
        "\n",
        "description += f\"\"\"\n",
        "---\n",
        "## 今回のリンク集({from_date}〜{to_date})\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "for i, (title, url) in enumerate(links):\n",
        "    description += f\"- {title}\\n{url}\\n\\n\"\n",
        "\n",
        "script_file_path = os.path.join(export_directory, \"description.txt\")\n",
        "f = open(script_file_path, mode=\"w\")\n",
        "f.write(description)\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}